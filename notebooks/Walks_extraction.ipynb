{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KQc_abMw4f0c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip uninstall -y python-louvain community\n",
        "!pip install aiohttp nest-asyncio rdflib python-louvain\n",
        "!git clone https://github.com/AlbezJelt/pyRDF2Vec\n",
        "!pip install ./pyRDF2Vec --use-feature=in-tree-build"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "eSsawUdN2eHE"
      },
      "outputs": [],
      "source": [
        "from pyrdf2vec import RDF2VecTransformer\n",
        "from pyrdf2vec.graphs import KG\n",
        "from pyrdf2vec import walkers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3hO6ts6X2VaA"
      },
      "outputs": [],
      "source": [
        "# set start entity for random walks\n",
        "entities_dbpedia = [\n",
        "    \"http://dbpedia.org/resource/Esports\"\n",
        "]\n",
        "\n",
        "entities_wikidata = [\n",
        "    'http://www.wikidata.org/entity/Q300920'  # Esports\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#set seed\n",
        "import random\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "eOnI8tjeH3eL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "7Bmd2KpEgPBN"
      },
      "outputs": [],
      "source": [
        "# Define our knowledge graph (here: DBPedia SPARQL endpoint).\n",
        "knowledge_graph_dbpedia = KG(\n",
        "    \"https://dbpedia.org/sparql\",\n",
        "    literals=[[\"http://dbpedia.org/ontology/wikiPageWikiLink\"]],\n",
        "    mul_req=True\n",
        ")\n",
        "\n",
        "# Define our knowledge graph for wikidata (here: Wikidata SPARQL endpoint).\n",
        "knowledge_graph_wikidata = KG(\n",
        "    \"https://query.wikidata.org/sparql\",\n",
        "    query_string=\"query\",\n",
        "    literals=[[\"http://www.w3.org/2004/02/skos/core#prefLabel\"]],\n",
        "    mul_req=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9kb0ls04pXXp"
      },
      "outputs": [],
      "source": [
        "# With with_reverse=True random walk starts from the provided entity (entity -> ... -> ... *max_depth*)\n",
        "# Then for each walk starts another random walk (each with max_depth=... and max_walks=...) but backwords (*max_depth* ... -> ... -> entity)\n",
        "# So max_walks*max_walks walks (*max_depth* ... -> ... -> entity -> ... -> ... *max_depth*) are produced\n",
        "\n",
        "walker = walkers.RandomWalker(\n",
        "    max_depth=3, max_walks=10, with_reverse=True, md5_bytes=None)\n",
        "\n",
        "# Create our transformer, setting the embedding & walking strategy.\n",
        "transformer = RDF2VecTransformer(\n",
        "    walkers=[walker],\n",
        "    verbose=1\n",
        ")\n",
        "# transformer and walker are the same for Dbpedia and wikidata\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "RMr8leA2gwrK",
        "outputId": "60560078-fc88-460f-a1a8-ae9b5426335f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using randomness = 0.85\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting walks from http://dbpedia.org/resource/Esports: 100%|██████████| 10/10 [00:48<00:00,  4.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 100 walks for 1 entities (52.6852s)\n"
          ]
        }
      ],
      "source": [
        "# extraction of random walks for dbpedia\n",
        "walks_dbpedia = transformer.get_walks(knowledge_graph_dbpedia, entities_dbpedia, 0.85)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mZ3C3N17g8ld",
        "outputId": "2927f4cb-a754-4fd2-8058-bf3d080e5c27",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using randomness = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting walks from http://www.wikidata.org/entity/Q300920: 100%|██████████| 10/10 [00:08<00:00,  1.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted 100 walks for 1 entities (10.9910s)\n"
          ]
        }
      ],
      "source": [
        "# ectraction of random walks for wikidata\n",
        "walks_wikidata = transformer.get_walks(knowledge_graph_wikidata, entities_wikidata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FQ1gWeBbeYP1"
      },
      "outputs": [],
      "source": [
        "# save dbpedia walks in a text file, not necessary, we already put in git repository our walks\n",
        "resource = [[[i.replace(\"http://dbpedia.org/resource/\", \"\") for i in j if i.startswith(\n",
        "    \"http://dbpedia.org/resource/\")] for j in k] for k in walks_dbpedia]\n",
        "with open('dbpedia_walks_final.txt', 'wt') as f:\n",
        "    for w in resource[0]:\n",
        "        f.write(' '.join(w) + '\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cTGf0VxV6fga"
      },
      "outputs": [],
      "source": [
        "# save wikidata walks in a text file, not necessary, we already put in git repository our walks\n",
        "resource = [[[i.replace(\"http://www.wikidata.org/entity/\", \"\") for i in j if i.startswith(\n",
        "    \"http://www.wikidata.org/entity/\")] for j in k] for k in walks_wikidata]\n",
        "with open('wikidata_walks_final.txt', 'wt') as f:\n",
        "    for w in resource[0]:\n",
        "        f.write(' '.join(w) + '\\n')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "walks_extraction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}