{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cade.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlbezJelt/compass-aligned-graph-embeddings/blob/main/notebooks/Cade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VY32oDsi1rki"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install folium==0.2.1\n",
        "!pip install git+https://github.com/valedica/gensim.git\n",
        "!pip install -U cade\n",
        "\n",
        "!wget https://raw.githubusercontent.com/AlbezJelt/compass-aligned-graph-embeddings/main/data/wiki_walks_from_dbpedia.txt\n",
        "!wget https://raw.githubusercontent.com/AlbezJelt/compass-aligned-graph-embeddings/main/data/wikidata_walks_final.txt\n",
        "!cat wiki_walks_from_dbpedia.txt wikidata_walks_final.txt >> compass.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cade.cade import CADE\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from scipy.spatial.distance import cosine\n",
        "from tqdm import tqdm\n",
        "\n",
        "import collections\n",
        "import warnings\n",
        "import json\n",
        "import requests\n",
        "from IPython.display import clear_output\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "WWtWSXR015T0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load dictionary with labels\n",
        "with requests.get(\"https://raw.githubusercontent.com/AlbezJelt/compass-aligned-graph-embeddings/main/data/wikidata_label_dictionary.json\", \"rt\") as req:\n",
        "  label_dict = json.loads(req.text)"
      ],
      "metadata": {
        "id": "ccAkr8E_fXGO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCADE(CADE):\n",
        "    def __init__(self, vocab, *args, **kwargs):\n",
        "        CADE.__init__(self, *args, **kwargs)\n",
        "        self.gvocab = vocab\n",
        "\n",
        "    def train_model(self, sentences):\n",
        "        model = None\n",
        "        if self.compass == None or self.init_mode != \"copy\":\n",
        "            model = Word2Vec(sg=self.sg, size=self.size, alpha=self.static_alpha, iter=self.static_iter,\n",
        "                                negative=self.negative,\n",
        "                                window=self.window, min_count=self.min_count, workers=self.workers)\n",
        "            # Modified trim rule to load a custom dictionary for the compass\n",
        "            trim_rule = self.internal_trimming_rule if self.compass != None or len(self.gvocab) != 0 else None\n",
        "            model.build_vocab(sentences, trim_rule=trim_rule)\n",
        "        if self.compass != None:\n",
        "            model = self.initialize_from_compass(model)\n",
        "        model.train(sentences, total_words=sum([len(s) for s in sentences]), epochs=model.iter, compute_loss=True)\n",
        "        return model"
      ],
      "metadata": {
        "id": "4WoTeun31Lc5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def create_vocabulary(compass_file:str, frequency:int, frequency_not:int):\n",
        "    with open(compass_file, 'rt') as f:\n",
        "        compass_corpus = map(lambda x: x.replace('\\n', ''), f.readlines())\n",
        "        compass_corpus = map(lambda x: x.split(' '), compass_corpus)\n",
        "        compass_corpus = (item for l in compass_corpus for item in l)\n",
        "        counter = collections.Counter(compass_corpus)\n",
        "        same_as = [k for (k, v) in counter.items() if v >= frequency and re.match(\"^Q\\d+$\", k)]\n",
        "        not_same_as = [j for (j, f) in counter.items() if f >= frequency_not and not re.match(\"^Q\\d+$\", j)]\n",
        "        vocab = set(not_same_as + same_as)\n",
        "        return list(vocab)"
      ],
      "metadata": {
        "id": "33dE_we-1Pph"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train compass\n",
        "# Vocabulary creation\n",
        "compass_vocab = create_vocabulary('compass.txt', 5, 20)\n",
        "aligner = CustomCADE(size=30, window=3, vocab=compass_vocab)\n",
        "aligner.train_compass(\"compass.txt\", overwrite=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_xDFjsd0SDj",
        "outputId": "d4ba2485-9973-46a9-ae8f-2fae66d4b64c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the compass from scratch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = aligner.train_slice(\"wiki_walks_from_dbpedia.txt\", save=True)\n",
        "model2 = aligner.train_slice(\"wikidata_walks_final.txt\", save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJC2xHAN0fdn",
        "outputId": "b42b1089-4b23-459f-df12-1061840bec07"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training embeddings: slice wiki_walks_from_dbpedia.txt.\n",
            "Initializing embeddings from compass.\n",
            "Training embeddings: slice wikidata_walks_final.txt.\n",
            "Initializing embeddings from compass.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# not owl:sameAs filtro manuale\n"
      ],
      "metadata": {
        "id": "TSdtbA2AgxMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('wiki_walks_from_dbpedia.txt', 'rt') as f:\n",
        "    compass_corpus = map(lambda x: x.replace('\\n', ''), f.readlines())\n",
        "    compass_corpus = list(map(lambda x: x.split(' '), compass_corpus))\n",
        "    compass_entities = (item for l in compass_corpus for item in l)\n",
        "    not_same_as = [j for j in compass_entities if not re.match(\"^Q\\d+$\", j)]\n",
        "    counter_nsa = collections.Counter(not_same_as)"
      ],
      "metadata": {
        "id": "f0yQK7SlT_u7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "keeped_entity = []\n",
        "checked_items = list(enumerate([(k, v) for (k, v) in counter_nsa.items() if v >=20]))\n",
        "for i, (entity, count) in checked_items:\n",
        "  print(f\"{i}/{len(checked_items)} - Most similar entities for {entity}:\")\n",
        "  pprint([label_dict[e] for (e, s) in model2.wv.similar_by_vector(model1.wv[entity], topn=20)])\n",
        "  mantieni = input(\"Keep the entity? (S/N, default S) \")\n",
        "  if mantieni.lower() == 's' or mantieni == '':\n",
        "    keeped_entity.append(entity)\n",
        "  clear_output(wait=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br1SXtX2V2Px",
        "outputId": "968a999b-25bd-4cdf-8fae-850f35df5d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42/43 - Most similar entities for Category:Television_series_by_ITV_Studios:\n",
            "['information system',\n",
            " 'techopedia.com',\n",
            " 'electrical connector',\n",
            " 'push-button',\n",
            " 'mouse button',\n",
            " 'electronics',\n",
            " 'plastic',\n",
            " 'left mouse button',\n",
            " 'taxonomic rank',\n",
            " 'spatial arrangement',\n",
            " 'Nintendo Entertainment System',\n",
            " 'n-tuple',\n",
            " 'Unix-like operating system',\n",
            " 'machine',\n",
            " 'computer case',\n",
            " 'form',\n",
            " 'film',\n",
            " 'Motherboard',\n",
            " 'Nintendo',\n",
            " 'Philips']\n",
            "Keep the entity? (S/N, default S)n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('keeped_not_same_as_entity.txt', 'wt') as f:\n",
        "  f.writelines(map(lambda x: f\"{x}\\n\", keeped_entity))"
      ],
      "metadata": {
        "id": "iUDGHekwe7KD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Caricamento vocaboli già filtrati"
      ],
      "metadata": {
        "id": "vFMqafINABB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/AlbezJelt/compass-aligned-graph-embeddings/main/data/keeped_not_same_as_entity.txt"
      ],
      "metadata": {
        "id": "Ni6S7g_dAHOS",
        "outputId": "d67f1102-aaf4-402e-99ab-a519375adb06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-18 18:03:51--  https://raw.githubusercontent.com/AlbezJelt/compass-aligned-graph-embeddings/main/data/keeped_not_same_as_entity.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 439 [text/plain]\n",
            "Saving to: ‘keeped_not_same_as_entity.txt’\n",
            "\n",
            "\r          keeped_no   0%[                    ]       0  --.-KB/s               \rkeeped_not_same_as_ 100%[===================>]     439  --.-KB/s    in 0s      \n",
            "\n",
            "2022-02-18 18:03:51 (12.2 MB/s) - ‘keeped_not_same_as_entity.txt’ saved [439/439]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('keeped_not_same_as_entity.txt', 'rt') as f:\n",
        "    nsa = map(lambda x: x.replace('\\n', ''), f.readlines())\n",
        "    keeped_entity = list(map(lambda x: x.split(' '), nsa))\n",
        "    keeped_entity = (item for l in keeped_entity for item in l)"
      ],
      "metadata": {
        "id": "84PRKmUNAaTp",
        "outputId": "f0b88ee6-5497-4d59-c2e2-1ccf765294d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object <genexpr> at 0x7f4af5877e50>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train dei modelli finali"
      ],
      "metadata": {
        "id": "d2adoGuZjAsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compass_vocab = create_vocabulary('compass.txt', 5, float('inf'))\n",
        "compass_vocab.extend(keeped_entity)\n",
        "aligner = CustomCADE(size=30, window=3, vocab=compass_vocab)\n",
        "aligner.train_compass(\"compass.txt\", overwrite=False)\n",
        "model1 = aligner.train_slice(\"wiki_walks_from_dbpedia.txt\", save=True)\n",
        "model2 = aligner.train_slice(\"wikidata_walks_final.txt\", save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjenEMnShOEo",
        "outputId": "28c3adfb-946c-4697-f6ae-e8f18966bb10"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the compass from scratch.\n",
            "Training embeddings: slice wiki_walks_from_dbpedia.txt.\n",
            "Initializing embeddings from compass.\n",
            "Training embeddings: slice wikidata_walks_final.txt.\n",
            "Initializing embeddings from compass.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Valutazione dei match, ordinati per conteggio totale delle entità"
      ],
      "metadata": {
        "id": "mV13a-5KOXIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('compass.txt', 'rt') as f:\n",
        "    compass_corpus = map(lambda x: x.replace('\\n', ''), f.readlines())\n",
        "    compass_corpus = list(map(lambda x: x.split(' '), compass_corpus))\n",
        "    compass_entities = [item for l in compass_corpus for item in l]\n",
        "    counter = collections.Counter(compass_entities)"
      ],
      "metadata": {
        "id": "9E0TB-lJIgg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entity shared by model1 and model2 vocabulary, ordered by total count in compass.txt\n",
        "counter_shared = [(k, v) for (k, v) in counter.most_common(len(counter.keys())) if k in model1.wv and k in model2.wv]"
      ],
      "metadata": {
        "id": "NcToLmbORQE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_matches_m1_to_m2 = [\n",
        "    (k, v) \n",
        "    for (k, v) \n",
        "    in counter_shared \n",
        "    if k in (\n",
        "        e\n",
        "        for (e, similarity)\n",
        "        in model2.wv.similar_by_vector(model1[k], topn=5)\n",
        "    )\n",
        "]\n",
        "\n",
        "similarity_matches_m1_to_m2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu0EJJb-Kw9i",
        "outputId": "0b0c2d04-a1f1-4fdc-c512-ec6a47a5bbc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Q11168', 72), ('Q248', 10), ('Q388', 10), ('Q1384', 5)]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_matches_m2_to_m1 = [\n",
        "    (k, v) \n",
        "    for (k, v) \n",
        "    in counter_shared \n",
        "    if k in (\n",
        "        e\n",
        "        for (e, similarity)\n",
        "        in model1.wv.similar_by_vector(model2[k], topn=5)\n",
        "    )\n",
        "]\n",
        "\n",
        "similarity_matches_m2_to_m1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOl6gXAPNH-A",
        "outputId": "5ab67986-09f8-4789-d05c-e7e54832e52d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Q349', 927),\n",
              " ('Q11410', 129),\n",
              " ('Q782919', 122),\n",
              " ('Q5830907', 119),\n",
              " ('Q362', 112),\n",
              " ('Q1194970', 51),\n",
              " ('Q9135', 16),\n",
              " ('Q173799', 6),\n",
              " ('Q127856', 5)]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Valutazione dei match, basata su distanza nel grafo"
      ],
      "metadata": {
        "id": "DkGQyB3MOpII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entities_around = []\n",
        "# Iter on every shared entity\n",
        "for e in tqdm([k for (k, v) in counter_shared]):\n",
        "    # Extract sentences with entity e\n",
        "    sentences = [sentence for sentence in compass_corpus if e in sentence]\n",
        "    e_in_s = []\n",
        "    # Iter over every sentence extracted\n",
        "    for s in sentences:\n",
        "        # Filter out entity from sentence if not in model1 and model2\n",
        "        # sf = [e for e in s if e in model1.wv and e in model2.wv]\n",
        "        sf = s\n",
        "        # Find indices for entity e\n",
        "        indices = [i for i, value in enumerate(sf) if value == e]  \n",
        "        # Iter over every indices founded  \n",
        "        for i in indices:\n",
        "            left = sf[max(i-2, 0):i] # Extract 2 entity from left\n",
        "            right = sf[i:min(i+2, len(s))] # Extract 2 entity from right\n",
        "            e_in_s = e_in_s + [l for l in left if not l == e] + [r for r in right if not r == e] # Combine the found entities\n",
        "    # Each item is a tuple (entity, counter of entity with distance 2)\n",
        "    entities_around.append((e, collections.Counter(e_in_s)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFdDUeXUOvEe",
        "outputId": "6cc39c21-3adb-4e5f-c350-2d3c286787bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 186/186 [00:01<00:00, 105.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can compare this lists with similarities\n",
        "# Example\n",
        "from pprint import pprint\n",
        "pprint(entities_around[30])\n",
        "pprint(model1.wv.similar_by_vector(entities_around[30][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCo90H7OVhyx",
        "outputId": "0070c82e-c0a5-46db-8cdf-916212e1d345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Q484876',\n",
            " Counter({'Q94933': 51,\n",
            "          'Q735267': 50,\n",
            "          'Category:Positions_of_authority': 50,\n",
            "          'Q6609399': 2,\n",
            "          'Q7414': 1,\n",
            "          'Q106075980': 1,\n",
            "          'Q2996165': 1,\n",
            "          'Q1961128': 1,\n",
            "          'Q1777832': 1,\n",
            "          'Q1404417': 1,\n",
            "          'Q167037': 1,\n",
            "          'Q6196402': 1,\n",
            "          'Q133080': 1,\n",
            "          'Q865588': 1,\n",
            "          'Q1255921': 1,\n",
            "          'Q5156251': 1,\n",
            "          'Q5467169': 1,\n",
            "          'Q5829580': 1,\n",
            "          'Q6270693': 1}))\n",
            "[('Q735267', 0.9858945608139038),\n",
            " ('Q94933', 0.9853776097297668),\n",
            " ('Category:Bank_robbery_in_fiction', 0.9402717351913452),\n",
            " ('Q17452', 0.8712246417999268),\n",
            " ('Q1853722', 0.8618626594543457),\n",
            " ('Q43134', 0.8591406941413879),\n",
            " ('Q5', 0.8497217297554016),\n",
            " ('Q15149723', 0.8457735180854797),\n",
            " ('Q2608796', 0.8359093070030212),\n",
            " ('Q5324150', 0.8292506337165833)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Valutazione per distanza delle parole"
      ],
      "metadata": {
        "id": "Pr58o0L2-4me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/AlbezJelt/compass-aligned-graph-embeddings/main/models/wiki_walks_from_dbpedia.model\n",
        "!wget https://raw.githubusercontent.com/AlbezJelt/compass-aligned-graph-embeddings/main/models/wikidata_walks_final.model"
      ],
      "metadata": {
        "id": "_o2pgU6X_EKr",
        "outputId": "aed64ee5-e0bd-466b-9614-a2b4e256a8ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-18 17:58:49--  https://raw.githubusercontent.com/AlbezJelt/compass-aligned-graph-embeddings/main/models/wiki_walks_from_dbpedia.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 311522 (304K) [application/octet-stream]\n",
            "Saving to: ‘wiki_walks_from_dbpedia.model’\n",
            "\n",
            "wiki_walks_from_dbp 100%[===================>] 304.22K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-02-18 17:58:49 (9.16 MB/s) - ‘wiki_walks_from_dbpedia.model’ saved [311522/311522]\n",
            "\n",
            "--2022-02-18 17:58:49--  https://raw.githubusercontent.com/AlbezJelt/compass-aligned-graph-embeddings/main/models/wikidata_walks_final.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 393614 (384K) [application/octet-stream]\n",
            "Saving to: ‘wikidata_walks_final.model’\n",
            "\n",
            "wikidata_walks_fina 100%[===================>] 384.39K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2022-02-18 17:58:49 (10.4 MB/s) - ‘wikidata_walks_final.model’ saved [393614/393614]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Word2Vec.load(\"wiki_walks_from_dbpedia.model\")\n",
        "model2 = Word2Vec.load(\"wikidata_walks_final.model\")"
      ],
      "metadata": {
        "id": "n036fZvR_Pc3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_list=[]\n",
        "with open('wiki_walks_from_dbpedia.txt', 'rt') as f:\n",
        "    dbpedia = map(lambda x: x.replace('\\n', ''), f.readlines())\n",
        "    dbpedia = list(map(lambda x: x.split(' '), dbpedia))\n",
        "    for l in dbpedia: \n",
        "      for item in l:\n",
        "        if not re.match(\"^Q\\d+$\", item) and item in keeped_entity:\n",
        "          db_list.append(item)\n",
        "        elif re.match(\"^Q\\d+$\", item):\n",
        "          db_list.append(item)"
      ],
      "metadata": {
        "id": "VWi-sPDQ_euK"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_list=[]\n",
        "with open('wikidata_walks_final.txt', 'rt') as f:\n",
        "    wiki = map(lambda x: x.replace('\\n', ''), f.readlines())\n",
        "    wiki = list(map(lambda x: x.split(' '), wiki))\n",
        "    for l in wiki:\n",
        "      for item in l:\n",
        "        wiki_list.append(item)"
      ],
      "metadata": {
        "id": "ShyStFsBG_Ba"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neighbour_wiki = []\n",
        "neighbour_db = []\n",
        "for index in range(0, len(wiki_list)):\n",
        "  if wiki_list[index] == \"Q300920\":\n",
        "    for ind in [index-3, index-2, index-1, index+1, index+2, index+3]:\n",
        "      neighbour_wiki.append(wiki_list[ind])\n",
        "\n",
        "for index in range(0, len(db_list)):\n",
        "  if db_list[index] == \"Q300920\":\n",
        "    for ind in [index-3, index-2, index-1, index+1, index+2, index+3]:\n",
        "      neighbour_db.append(db_list[ind])\n",
        "\n",
        "counter_wiki = collections.Counter(neighbour_wiki)\n",
        "counter_db = collections.Counter(neighbour_db)\n"
      ],
      "metadata": {
        "id": "RqHgJ5-j_gTn"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_words=[]\n",
        "db_words=[]\n",
        "for l in counter_wiki.most_common(10):\n",
        "  wiki_words.append(l[0])\n",
        "\n",
        "for l in counter_db.most_common(10):\n",
        "  db_words.append(l[0])\n",
        "\n",
        "similar = []\n",
        "for db in db_words:\n",
        "  for wiki in wiki_words:\n",
        "    sim = 1 - cosine(model1[db],model2[wiki])\n",
        "    similar.append([label_dict[db], label_dict[wiki], sim])"
      ],
      "metadata": {
        "id": "_Mcfk22fJecz"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install xlsxwriter"
      ],
      "metadata": {
        "id": "-PiLRbMYL9Ne",
        "outputId": "1c65f71b-3987-4f9c-cfb5-19406771e5b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.0.2-py3-none-any.whl (149 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▏                             | 10 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 20 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 30 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 40 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 51 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 61 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 81 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 92 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 102 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 112 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 122 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 133 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 143 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 149 kB 4.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xlsxwriter\n",
        "similar.insert(0,[\"Dbpedia\", \"Wikidata\", \"Similarity\"])\n",
        "\n",
        "with xlsxwriter.Workbook('similar.xlsx') as workbook:\n",
        "    worksheet = workbook.add_worksheet()\n",
        "\n",
        "    for row_num, data in enumerate(similar):\n",
        "        worksheet.write_row(row_num, 0, data)"
      ],
      "metadata": {
        "id": "d5gTONdtMFoG"
      },
      "execution_count": 97,
      "outputs": []
    }
  ]
}