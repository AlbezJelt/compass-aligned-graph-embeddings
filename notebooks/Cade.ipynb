{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prove con similarit√†.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlbezJelt/compass-aligned-graph-embeddings/blob/main/notebooks/Cade.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VY32oDsi1rki"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install folium==0.2.1\n",
        "!pip install git+https://github.com/valedica/gensim.git\n",
        "!pip install -U cade\n",
        "\n",
        "!wget https://raw.githubusercontent.com/AlbezJelt/compass-aligned-graph-embeddings/main/data/wiki_walks_from_dbpedia.txt\n",
        "!wget https://raw.githubusercontent.com/AlbezJelt/compass-aligned-graph-embeddings/main/data/wikidata_walks_final.txt\n",
        "!cat wiki_walks_from_dbpedia.txt wikidata_walks_final.txt >> compass.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cade.cade import CADE\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "from scipy.spatial.distance import cosine\n",
        "from tqdm import tqdm\n",
        "\n",
        "import collections\n",
        "import warnings\n",
        "import json\n",
        "import requests\n",
        "from IPython.display import clear_output\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "WWtWSXR015T0"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load dictionary with labels\n",
        "with requests.get(\"https://raw.githubusercontent.com/AlbezJelt/compass-aligned-graph-embeddings/main/data/wikidata_label_dictionary.json\", \"rt\") as req:\n",
        "  label_dict = json.loads(req.text)"
      ],
      "metadata": {
        "id": "ccAkr8E_fXGO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomCADE(CADE):\n",
        "    def __init__(self, vocab, *args, **kwargs):\n",
        "        CADE.__init__(self, *args, **kwargs)\n",
        "        self.gvocab = vocab\n",
        "\n",
        "    def train_model(self, sentences):\n",
        "        model = None\n",
        "        if self.compass == None or self.init_mode != \"copy\":\n",
        "            model = Word2Vec(sg=self.sg, size=self.size, alpha=self.static_alpha, iter=self.static_iter,\n",
        "                                negative=self.negative,\n",
        "                                window=self.window, min_count=self.min_count, workers=self.workers)\n",
        "            # Modified trim rule to load a custom dictionary for the compass\n",
        "            trim_rule = self.internal_trimming_rule if self.compass != None or len(self.gvocab) != 0 else None\n",
        "            model.build_vocab(sentences, trim_rule=trim_rule)\n",
        "        if self.compass != None:\n",
        "            model = self.initialize_from_compass(model)\n",
        "        model.train(sentences, total_words=sum([len(s) for s in sentences]), epochs=model.iter, compute_loss=True)\n",
        "        return model"
      ],
      "metadata": {
        "id": "4WoTeun31Lc5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def create_vocabulary(compass_file:str, frequency:int, frequency_not:int):\n",
        "    with open(compass_file, 'rt') as f:\n",
        "        compass_corpus = map(lambda x: x.replace('\\n', ''), f.readlines())\n",
        "        compass_corpus = map(lambda x: x.split(' '), compass_corpus)\n",
        "        compass_corpus = (item for l in compass_corpus for item in l)\n",
        "        counter = collections.Counter(compass_corpus)\n",
        "        same_as = [k for (k, v) in counter.items() if v >= frequency and re.match(\"^Q\\d+$\", k)]\n",
        "        not_same_as = [j for (j, f) in counter.items() if f >= frequency_not and not re.match(\"^Q\\d+$\", j)]\n",
        "        vocab = set(not_same_as + same_as)\n",
        "        return list(vocab)"
      ],
      "metadata": {
        "id": "33dE_we-1Pph"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train compass\n",
        "# Vocabulary creation\n",
        "compass_vocab = create_vocabulary('compass.txt', 5, 20)\n",
        "aligner = CustomCADE(size=30, window=3, vocab=compass_vocab)\n",
        "aligner.train_compass(\"compass.txt\", overwrite=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_xDFjsd0SDj",
        "outputId": "c2b5539c-3e0c-43a7-f077-c47fab557b16"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the compass from scratch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = aligner.train_slice(\"wiki_walks_from_dbpedia.txt\", save=True)\n",
        "model2 = aligner.train_slice(\"wikidata_walks_final.txt\", save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJC2xHAN0fdn",
        "outputId": "a63aa0ac-46b6-45ae-8dbc-a1cd1df93be1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training embeddings: slice wiki_walks_from_dbpedia.txt.\n",
            "Initializing embeddings from compass.\n",
            "Training embeddings: slice wikidata_walks_final.txt.\n",
            "Initializing embeddings from compass.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# not owl:sameAs filtro manuale\n"
      ],
      "metadata": {
        "id": "TSdtbA2AgxMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('wiki_walks_from_dbpedia.txt', 'rt') as f:\n",
        "    compass_corpus = map(lambda x: x.replace('\\n', ''), f.readlines())\n",
        "    compass_corpus = list(map(lambda x: x.split(' '), compass_corpus))\n",
        "    compass_entities = (item for l in compass_corpus for item in l)\n",
        "    not_same_as = [j for j in compass_entities if not re.match(\"^Q\\d+$\", j)]\n",
        "    counter_nsa = collections.Counter(not_same_as)"
      ],
      "metadata": {
        "id": "f0yQK7SlT_u7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "keeped_entity = []\n",
        "checked_items = list(enumerate([(k, v) for (k, v) in counter_nsa.items() if v >=20]))\n",
        "for i, (entity, count) in checked_items:\n",
        "  print(f\"{i}/{len(checked_items)} - Most similar entities for {entity}:\")\n",
        "  pprint([label_dict[e] for (e, s) in model2.wv.similar_by_vector(model1.wv[entity], topn=20)])\n",
        "  mantieni = input(\"Keep the entity? (S/N, default S) \")\n",
        "  if mantieni.lower() == 's' or mantieni == '':\n",
        "    keeped_entity.append(entity)\n",
        "  clear_output(wait=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Br1SXtX2V2Px",
        "outputId": "968a999b-25bd-4cdf-8fae-850f35df5d1a"
      },
      "execution_count": 44,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "42/43 - Most similar entities for Category:Television_series_by_ITV_Studios:\n",
            "['information system',\n",
            " 'techopedia.com',\n",
            " 'electrical connector',\n",
            " 'push-button',\n",
            " 'mouse button',\n",
            " 'electronics',\n",
            " 'plastic',\n",
            " 'left mouse button',\n",
            " 'taxonomic rank',\n",
            " 'spatial arrangement',\n",
            " 'Nintendo Entertainment System',\n",
            " 'n-tuple',\n",
            " 'Unix-like operating system',\n",
            " 'machine',\n",
            " 'computer case',\n",
            " 'form',\n",
            " 'film',\n",
            " 'Motherboard',\n",
            " 'Nintendo',\n",
            " 'Philips']\n",
            "Keep the entity? (S/N, default S)n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('keeped_not_same_as_entity.txt', 'wt') as f:\n",
        "  f.writelines(map(lambda x: f\"{x}\\n\", keeped_entity))"
      ],
      "metadata": {
        "id": "iUDGHekwe7KD"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train dei modelli finali"
      ],
      "metadata": {
        "id": "d2adoGuZjAsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compass_vocab = create_vocabulary('compass.txt', 5, float('inf'))\n",
        "compass_vocab.extend(keeped_entity)\n",
        "aligner = CustomCADE(size=30, window=3, vocab=compass_vocab)\n",
        "aligner.train_compass(\"compass.txt\", overwrite=False)\n",
        "model1 = aligner.train_slice(\"wiki_walks_from_dbpedia.txt\", save=True)\n",
        "model2 = aligner.train_slice(\"wikidata_walks_final.txt\", save=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjenEMnShOEo",
        "outputId": "ffd9f1d1-dd71-40cc-d1e2-9dc2ef1b5f67"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the compass from scratch.\n",
            "Training embeddings: slice wiki_walks_from_dbpedia.txt.\n",
            "Initializing embeddings from compass.\n",
            "Training embeddings: slice wikidata_walks_final.txt.\n",
            "Initializing embeddings from compass.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Valutazione dei match, ordinati per conteggio totale delle entit√†"
      ],
      "metadata": {
        "id": "mV13a-5KOXIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('compass.txt', 'rt') as f:\n",
        "    compass_corpus = map(lambda x: x.replace('\\n', ''), f.readlines())\n",
        "    compass_corpus = list(map(lambda x: x.split(' '), compass_corpus))\n",
        "    compass_entities = [item for l in compass_corpus for item in l]\n",
        "    counter = collections.Counter(compass_entities)"
      ],
      "metadata": {
        "id": "9E0TB-lJIgg6"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entity shared by model1 and model2 vocabulary, ordered by total count in compass.txt\n",
        "counter_shared = [(k, v) for (k, v) in counter.most_common(len(counter.keys())) if k in model1.wv and k in model2.wv]"
      ],
      "metadata": {
        "id": "NcToLmbORQE3"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_matches_m1_to_m2 = [\n",
        "    (k, v) \n",
        "    for (k, v) \n",
        "    in counter_shared \n",
        "    if k in (\n",
        "        e\n",
        "        for (e, similarity)\n",
        "        in model2.wv.similar_by_vector(model1[k], topn=5)\n",
        "    )\n",
        "]\n",
        "\n",
        "similarity_matches_m1_to_m2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu0EJJb-Kw9i",
        "outputId": "0b0c2d04-a1f1-4fdc-c512-ec6a47a5bbc4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Q11168', 72), ('Q248', 10), ('Q388', 10), ('Q1384', 5)]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "similarity_matches_m2_to_m1 = [\n",
        "    (k, v) \n",
        "    for (k, v) \n",
        "    in counter_shared \n",
        "    if k in (\n",
        "        e\n",
        "        for (e, similarity)\n",
        "        in model1.wv.similar_by_vector(model2[k], topn=5)\n",
        "    )\n",
        "]\n",
        "\n",
        "similarity_matches_m2_to_m1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOl6gXAPNH-A",
        "outputId": "5ab67986-09f8-4789-d05c-e7e54832e52d"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Q349', 927),\n",
              " ('Q11410', 129),\n",
              " ('Q782919', 122),\n",
              " ('Q5830907', 119),\n",
              " ('Q362', 112),\n",
              " ('Q1194970', 51),\n",
              " ('Q9135', 16),\n",
              " ('Q173799', 6),\n",
              " ('Q127856', 5)]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Valutazione dei match, basata su distanza nel grafo"
      ],
      "metadata": {
        "id": "DkGQyB3MOpII"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "entities_around = []\n",
        "# Iter on every shared entity\n",
        "for e in tqdm([k for (k, v) in counter_shared]):\n",
        "    # Extract sentences with entity e\n",
        "    sentences = [sentence for sentence in compass_corpus if e in sentence]\n",
        "    e_in_s = []\n",
        "    # Iter over every sentence extracted\n",
        "    for s in sentences:\n",
        "        # Filter out entity from sentence if not in model1 and model2\n",
        "        # sf = [e for e in s if e in model1.wv and e in model2.wv]\n",
        "        sf = s\n",
        "        # Find indices for entity e\n",
        "        indices = [i for i, value in enumerate(sf) if value == e]  \n",
        "        # Iter over every indices founded  \n",
        "        for i in indices:\n",
        "            left = sf[max(i-2, 0):i] # Extract 2 entity from left\n",
        "            right = sf[i:min(i+2, len(s))] # Extract 2 entity from right\n",
        "            e_in_s = e_in_s + [l for l in left if not l == e] + [r for r in right if not r == e] # Combine the found entities\n",
        "    # Each item is a tuple (entity, counter of entity with distance 2)\n",
        "    entities_around.append((e, collections.Counter(e_in_s)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFdDUeXUOvEe",
        "outputId": "6cc39c21-3adb-4e5f-c350-2d3c286787bc"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 186/186 [00:01<00:00, 105.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we can compare this lists with similarities\n",
        "# Example\n",
        "from pprint import pprint\n",
        "pprint(entities_around[30])\n",
        "pprint(model1.wv.similar_by_vector(entities_around[30][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCo90H7OVhyx",
        "outputId": "0070c82e-c0a5-46db-8cdf-916212e1d345"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('Q484876',\n",
            " Counter({'Q94933': 51,\n",
            "          'Q735267': 50,\n",
            "          'Category:Positions_of_authority': 50,\n",
            "          'Q6609399': 2,\n",
            "          'Q7414': 1,\n",
            "          'Q106075980': 1,\n",
            "          'Q2996165': 1,\n",
            "          'Q1961128': 1,\n",
            "          'Q1777832': 1,\n",
            "          'Q1404417': 1,\n",
            "          'Q167037': 1,\n",
            "          'Q6196402': 1,\n",
            "          'Q133080': 1,\n",
            "          'Q865588': 1,\n",
            "          'Q1255921': 1,\n",
            "          'Q5156251': 1,\n",
            "          'Q5467169': 1,\n",
            "          'Q5829580': 1,\n",
            "          'Q6270693': 1}))\n",
            "[('Q735267', 0.9858945608139038),\n",
            " ('Q94933', 0.9853776097297668),\n",
            " ('Category:Bank_robbery_in_fiction', 0.9402717351913452),\n",
            " ('Q17452', 0.8712246417999268),\n",
            " ('Q1853722', 0.8618626594543457),\n",
            " ('Q43134', 0.8591406941413879),\n",
            " ('Q5', 0.8497217297554016),\n",
            " ('Q15149723', 0.8457735180854797),\n",
            " ('Q2608796', 0.8359093070030212),\n",
            " ('Q5324150', 0.8292506337165833)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entit√† interessanti di esempio\n",
        "\n",
        "Se vogliamo portare qualche esempio di similarit√†\n",
        "\n"
      ],
      "metadata": {
        "id": "Y7OmD-9TZHB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with requests.get(\"https://raw.githubusercontent.com/AlbezJelt/compass-aligned-graph-embeddings/main/data/wikidata_label_dictionary.json\", \"rt\") as req:\n",
        "  label_dict = json.loads(req.text)\n",
        "\n",
        "print(label_dict['Q210167'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGaxhe6wZEAp",
        "outputId": "2c2f231d-be14-4deb-8d3c-0918c5d173cf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "video game developer\n"
          ]
        }
      ]
    }
  ]
}